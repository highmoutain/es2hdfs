# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.
spark.eventLog.enabled           true
spark.eventLog.dir               hdfs:///sparkhistoryserver
  spark.eventLog.compress          true
# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=one two three
spark.master                     yarn
spark.submit.deployMode         cluster
#spark.executor.extraClassPath /home/hadoop/dmp-udf-0.0.1-SNAPSHOT.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/hbase-client-1.1.1.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/hbase-common-1.1.1.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/hbase-protocol-1.1.1.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/hbase-server-1.1.1.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/hive-hbase-handler-1.2.0.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/htrace-core-3.1.0-incubating.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/guava-12.0.1.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/protobuf-java-2.5.0.jar
#spark.driver.extraClassPath /home/hadoop/dmp-udf-0.0.1-SNAPSHOT.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/lib/mysql-connector-java-5.1.36.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/hbase-client-1.1.1.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/hbase-common-1.1.1.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/hbase-protocol-1.1.1.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/hbase-server-1.1.1.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/hive-hbase-handler-1.2.0.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/htrace-core-3.1.0-incubating.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/guava-12.0.1.jar:/home/hadoop/spark-1.6.2-bin-hadoop2.7/auxlib/protobuf-java-2.5.0.jar
#spark.driver.extraClassPath /home/hadoop/spark-2.1.1-bin-hadoop2.7/lib/mysql-connector-java-5.1.36.jar:/home/hadoop/spark-2.2.1-bin-hadoop2.7/carbonlib/apache-carbondata-1.3.1-bin-spark2.2.1-hadoop2.7.2.jar
spark.driver.extraClassPath /home/hadoop/spark-2.1.1-bin-hadoop2.7/lib/mysql-connector-java-5.1.36.jar: /home/hadoop/spark-2.2.1-bin-hadoop2.7/carbonlib/*:/home/hadoop/elasticsearch-spark-20_2.11-5.1.1.jar
spark.kryoserializer.buffer 200m
spark.kryoserializer.buffer.max 200m
#spark.executor.cores 1
#spark.cores.max 10
spark.executor.instances 6
spark.executor.cores 10
spark.executor.memory 25G
spark.driver.memory 6G
spark.shuffle.consolidateFiles true
spark.default.parallelism 20
spark.sql.shuffle.partitions 20
#spark.speculation true
spark.ui.port 4040
spark.driver.port = 20002
spark.driver.host = 172.20.40.18
spark.yarn.dist.files /home/hadoop/spark-2.2.1-bin-hadoop2.7/conf/carbon.properties, /home/hadoop/spark-2.2.1-bin-hadoop2.7/conf/hive-site.xml, /home/hadoop/elasticsearch-spark-20_2.11-5.1.1.jar, /home/hadoop/config.properties
#spark.yarn.dist.archives /home/hadoop/spark-2.2.1-bin-hadoop2.7/carbonlib/carbondata.tar.gz
#spark.executor.extraJavaOptions -Dcarbon.properties.filepath=carbon.properties
#spark.executor.extraClassPath /home/hadoop/spark-2.2.1-bin-hadoop2.7/carbonlib/apache-carbondata-1.3.1-bin-spark2.2.1-hadoop2.7.2.jar
#spark.executor.extraClassPath carbondata.tar.gz/carbonlib/*:elasticsearch-spark-20_2.11-5.1.1.jar
spark.driver.extraJavaOptions -Dcarbon.properties.filepath = /home/hadoop/spark-2.2.1-bin-hadoop2.7/conf/carbon.properties
spark.yarn.am.memory 6G
spark.debug.maxToStringFields 200000
spark.yarn.archive hdfs:///sparkapp/jars
  spark.yarn.preserve.staging.files  true
#spark.driver.extraClassPath ./
#spark.executor.extraClassPath ./
